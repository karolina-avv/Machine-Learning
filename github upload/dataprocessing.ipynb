{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a075868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38ad527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_extract_features(directory):\n",
    "    # Initialize lists to store features and labels\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate through each file in the directory\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".mp3\"):\n",
    "            file_path = os.path.join(directory, file)\n",
    "            try:\n",
    "                # Load audio file \n",
    "                audio, sr = librosa.load(file_path, sr=None)\n",
    "                # Extract MFCC features\n",
    "                mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "                # Flatten the MFCC matrix into a 1D array\n",
    "                flattened_mfccs = np.ravel(mfccs)\n",
    "                # Append features and label\n",
    "                features.append(flattened_mfccs)\n",
    "                label = int(file.split('.')[0])  # Extract numerical label from file name\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file}: {e}\")\n",
    "            \n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Directory containing MP3 files\n",
    "train_directory = \"train_mp3s\"\n",
    "\n",
    "# Load and extract features from MP3 files\n",
    "train_features, train_labels = load_and_extract_features(train_directory)\n",
    "\n",
    "# Print shape of features and labels\n",
    "#print(\"Shape of features:\", train_features.shape)\n",
    "#print(\"Shape of labels:\", train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89dc1e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(features):\n",
    "    # Compute mean and standard deviation along the feature axis (axis=0)\n",
    "    mean = np.mean(features, axis=0)\n",
    "    std = np.std(features, axis=0)\n",
    "    # Normalize features\n",
    "    normalized_features = (features - mean) / std\n",
    "    return normalized_features\n",
    "\n",
    "# Normalize features\n",
    "train_features_normalized = normalize_features(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9726747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Label: [0. 0. 0. ... 0. 0. 0.]\n",
      "Encoded Label: [0. 0. 0. ... 0. 0. 0.]\n",
      "Encoded Label: [0. 0. 0. ... 0. 0. 0.]\n",
      "Encoded Label: [0. 0. 0. ... 0. 0. 0.]\n",
      "Encoded Label: [0. 0. 0. ... 0. 0. 0.]\n",
      "Stored 'train_features_normalized' (ndarray)\n",
      "Stored 'train_labels_encoded' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode_labels(labels):\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded_labels = label_encoder.fit_transform(labels)\n",
    "    one_hot_labels = np.eye(len(label_encoder.classes_))[integer_encoded_labels]\n",
    "    return one_hot_labels\n",
    "\n",
    "# One-hot encode labels\n",
    "train_labels_encoded = one_hot_encode_labels(train_labels)\n",
    "for i in range(5):\n",
    "    print(\"Encoded Label:\", train_labels_encoded[i])\n",
    "    \n",
    "%store train_features_normalized\n",
    "%store train_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0657f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1\n",
      "Features: [-3.0473273e+02 -2.9553900e+02 -2.7947311e+02 ...  6.7996035e+00\n",
      "  6.6225834e+00  1.0578364e-01]\n",
      "Label: 11828\n",
      "Encoded Label: [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      "Sample 2\n",
      "Features: [-524.09937   -465.32596   -372.59537   ...    4.410584    -3.2377188\n",
      "   -1.8789346]\n",
      "Label: 10288\n",
      "Encoded Label: [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      "Sample 3\n",
      "Features: [-338.7017   -312.87903  -307.57935  ...  -12.200284  -12.266375\n",
      "  -16.150473]\n",
      "Label: 2917\n",
      "Encoded Label: [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      "Sample 4\n",
      "Features: [-192.2961   -166.82129  -161.0721   ...  -11.767268   -7.696413\n",
      "   -7.371523]\n",
      "Label: 11196\n",
      "Encoded Label: [0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      "Sample 5\n",
      "Features: [-410.59158  -350.48175  -284.245    ...  -16.669434  -20.310028\n",
      "  -21.406288]\n",
      "Label: 9842\n",
      "Encoded Label: [0. 0. 0. ... 0. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):  # Print 5 samples for inspection\n",
    "    print(\"Sample\", i+1)\n",
    "    print(\"Features:\", train_features[i])  # Print features\n",
    "    print(\"Label:\", train_labels[i])  # Print label before encoding\n",
    "    print(\"Encoded Label:\", train_labels_encoded[i])  # Print encoded label\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9646782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 0  # Change this to the index of the sample you want to print\n",
    "\n",
    "# Print features\n",
    "print(\"Features:\")\n",
    "print(train_features[sample_index])\n",
    "\n",
    "# Print label\n",
    "print(\"Label:\", train_labels[sample_index])\n",
    "\n",
    "# Print encoded label\n",
    "print(\"Encoded Label:\")\n",
    "print(train_labels_encoded[sample_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dff9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "import librosa.display\n",
    "\n",
    "def preprocess_audio(file_path, target_shape=(128, 128)):\n",
    "    # Load audio file\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    \n",
    "    # Compute mel-spectrogram\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "    \n",
    "    # Resize spectrogram to the target shape\n",
    "    mel_spec_resized = resize(mel_spec, target_shape)\n",
    "    \n",
    "    # Convert to decibel scale (log scale)\n",
    "    mel_spec_db = librosa.amplitude_to_db(mel_spec_resized, ref=np.max)\n",
    "    \n",
    "    # Normalize spectrogram to [0, 1]\n",
    "    mel_spec_normalized = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min())\n",
    "    \n",
    "    return mel_spec_normalized\n",
    "\n",
    "def preprocess_audio_folder(folder_path, target_shape=(128, 128)):\n",
    "    all_spectrograms = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if file_name.endswith(\".mp3\"):\n",
    "            spectrogram = preprocess_audio(file_path, target_shape=target_shape)\n",
    "            all_spectrograms.append(spectrogram)\n",
    "    # Stack or concatenate all spectrograms along a new axis to form a single tensor or array\n",
    "    return np.stack(all_spectrograms)\n",
    "\n",
    "# Example usage:\n",
    "folder_path = \"train_mp3s\"\n",
    "all_spectrograms = preprocess_audio_folder(folder_path)\n",
    "print(\"All spectrograms shape:\", all_spectrograms.shape)\n",
    "\n",
    "%store all_spectrograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86d49ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(type(train_features_normalized))\n",
    "\n",
    "train_features_normalized_df = pd.DataFrame(train_features_normalized)\n",
    "\n",
    "# Save to CSV\n",
    "train_features_normalized_df.to_csv('audio_features.csv', index=False)\n",
    "train_features_normalized = pd.read_csv('audio_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26900cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
      "       ...\n",
      "       '11876', '11877', '11878', '11879', '11880', '11881', '11882', '11883',\n",
      "       '11884', '11885'],\n",
      "      dtype='object', length=11886)\n"
     ]
    }
   ],
   "source": [
    "train_labels_encoded_df = pd.DataFrame(train_labels_encoded)\n",
    "\n",
    "train_labels_encoded_df.to_csv('audio_labels.csv', index=False)\n",
    "train_labels_encoded = pd.read_csv('audio_labels.csv')\n",
    "print(train_labels_encoded_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a0e6f95",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'audio_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m     34\u001b[0m X \u001b[38;5;241m=\u001b[39m train_features_normalized_df\u001b[38;5;241m.\u001b[39mvalues  \u001b[38;5;66;03m# Assuming your features are already stored as numpy arrays in the CSV\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m Y \u001b[38;5;241m=\u001b[39m train_labels_encoded_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_labels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Convert X_upsample and Y_upsample to float32\u001b[39;00m\n\u001b[1;32m     38\u001b[0m X_upsample \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'audio_labels'"
     ]
    }
   ],
   "source": [
    "class CNN_audio:\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize the CNN\n",
    "        classifier = Sequential()\n",
    "        # Step 1 - Convolution\n",
    "        classifier.add(Conv1D(60, 10, input_shape=(40000, 74), activation='relu'))\n",
    "        # Step 2 - Pooling\n",
    "        classifier.add(MaxPooling1D(pool_size=3))\n",
    "        # Adding a second convolutional layer\n",
    "        classifier.add(Conv1D(30, 5, activation='relu'))\n",
    "        classifier.add(MaxPooling1D(pool_size=3))\n",
    "        classifier.add(Conv1D(15, 5, activation='relu'))\n",
    "        classifier.add(MaxPooling1D(pool_size=3))\n",
    "        # Step 3 - Flattening\n",
    "        classifier.add(Flatten())\n",
    "        classifier.add(Dropout(0.5))\n",
    "        # Step 4 - Full connection\n",
    "        classifier.add(Dense(units=128, activation='relu'))\n",
    "        classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "        # Compiling the CNN\n",
    "        classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def modelFit(self, X, Y, epoch=10):\n",
    "        history = self.classifier.fit(X, Y, epochs=epoch)\n",
    "        return history\n",
    "\n",
    "    def modelPredict(self, X):\n",
    "        return self.classifier.predict(X)\n",
    "\n",
    "    \n",
    "X = train_features_normalized_df.values  # Assuming your features are already stored as numpy arrays in the CSV\n",
    "Y = train_labels_encoded_df['audio_labels'].values\n",
    "\n",
    "# Convert X_upsample and Y_upsample to float32\n",
    "X_upsample = X.astype(np.float32)\n",
    "Y_upsample = Y.astype(np.float32)\n",
    "\n",
    "# Create an instance of the CNN model\n",
    "model = CNN_audio()\n",
    "\n",
    "# Fit the model to your data\n",
    "history = model.modelFit(X_upsample, Y_upsample, epoch=5)\n",
    "\n",
    "# Convert X to float32 if needed\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "# Create an instance of the CNN model\n",
    "model = CNN_audio()\n",
    "\n",
    "# Fit the model to your data\n",
    "history = model.modelFit(X, Y, epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed20f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
